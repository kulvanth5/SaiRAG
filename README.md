In this work, I had developed a RAG application which combines language models with vector database to improve the quality and relevance of information retrieval. The core of the application utilizes BERT for text vectorization, which allows for the transformation of textual content into dense vector representations. These vectorized forms make it easier to match and retrieve contextually relevant information, forming the foundation for context-aware responses. I had leveraged Qdrant, a vector database optimized for managing and querying high-dimensional data.

To build an efficient pipeline, I first focused on gathering and structuring the dataset. I sourced textual content from [saispeaks.sathyasai.org](https://saispeaks.sathyasai.org/), an extensive archive that required web scraping for data extraction. Using BeautifulSoup, I automated the extraction of text from web pages, ensuring accuracy and completeness in the retrieval of relevant information. After gathering the raw text data, I employed Pandas for pre-processing, which involved cleaning, organizing, and structuring the text for efficient downstream processing.

Finally, I integrated Mistral 8B, to generate responses based on the context retrieved from the Qdrant database. 

So the work flow of the application is - when a query is sent as an input, the application retrieves relevant information from Qdrant, and Mistral 8B generates a coherent response that aligns with the retrieved context. This combination of retrieval and generation enables the application to deliver responses that are both contextually accurate and human-like in quality. Together, the system components create a robust workflow where relevant data is retrieved, structured, and processed to produce meaningful and insightful responses.
